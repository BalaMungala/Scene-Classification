{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Building the CNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dd=pd.read_csv(\"E://Analytics Vidhya//Intel Scene//test_WyRytb0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "for i in dd['image_name'].values:\n",
    "        test_image = image.load_img('E://Analytics Vidhya//Intel Scene//train-scene classification//train//{}'.format(i))\n",
    "        test_image.save(\"E://Analytics Vidhya//Intel Scene//train-scene classification//test_images//{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "for i in dd['image_name'].values:\n",
    "        test_image = image.load_img('E://Analytics Vidhya//Intel Scene//train-scene classification//train//{}'.format(i))\n",
    "        test_image.save(\"E://Analytics Vidhya//Intel Scene//train-scene classification//train_images//{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dt=pd.read_csv(\"E://Analytics Vidhya//Intel Scene//train-scene classification//train.csv\")\n",
    "\n",
    "building=[]\n",
    "forest=[]\n",
    "glacier=[]\n",
    "mountain=[]\n",
    "sea=[]\n",
    "street=[]\n",
    "\n",
    "\n",
    "building.append(dt.iloc[dt['label'].values==0]['image_name'])\n",
    "forest.append(dt.iloc[dt['label'].values==1]['image_name'])\n",
    "glacier.append(dt.iloc[dt['label'].values==2]['image_name'])\n",
    "mountain.append(dt.iloc[dt['label'].values==3]['image_name'])\n",
    "sea.append(dt.iloc[dt['label'].values==4]['image_name'])\n",
    "street.append(dt.iloc[dt['label'].values==5]['image_name'])\n",
    "\n",
    "            \n",
    "buildings=np.array(building).ravel()\n",
    "forests=np.array(forest).ravel()\n",
    "glaciers=np.array(glacier).ravel()\n",
    "mountains=np.array(mountain).ravel()\n",
    "seas=np.array(sea).ravel()\n",
    "streets=np.array(street).ravel()            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "for i in buildings:\n",
    "        test_image = image.load_img('E://Analytics Vidhya//Intel Scene//train-scene classification//train_images//{}'.format(i))\n",
    "        test_image.save(\"E://Analytics Vidhya//Intel Scene//train-scene classification//building//{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "for i in forests:\n",
    "        test_image = image.load_img('E://Analytics Vidhya//Intel Scene//train-scene classification//train_images//{}'.format(i))\n",
    "        test_image.save(\"E://Analytics Vidhya//Intel Scene//train-scene classification//forest//{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "for i in glaciers:\n",
    "        test_image = image.load_img('E://Analytics Vidhya//Intel Scene//train-scene classification//train_images//{}'.format(i))\n",
    "        test_image.save(\"E://Analytics Vidhya//Intel Scene//train-scene classification//glacier//{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "for i in mountains:\n",
    "        test_image = image.load_img('E://Analytics Vidhya//Intel Scene//train-scene classification//train_images//{}'.format(i))\n",
    "        test_image.save(\"E://Analytics Vidhya//Intel Scene//train-scene classification//mountain//{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "for i in seas:\n",
    "        test_image = image.load_img('E://Analytics Vidhya//Intel Scene//train-scene classification//train_images//{}'.format(i))\n",
    "        test_image.save(\"E://Analytics Vidhya//Intel Scene//train-scene classification//sea//{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "for i in streets:\n",
    "        test_image = image.load_img('E://Analytics Vidhya//Intel Scene//train-scene classification//train_images//{}'.format(i))\n",
    "        test_image.save(\"E://Analytics Vidhya//Intel Scene//train-scene classification//street//{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 6, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17034 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('E://Analytics Vidhya//Intel Scene//train-scene classification//train_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "path=\"E://Analytics Vidhya//Intel Scene//weights//intelimg_classify_weights.{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "mcp=ModelCheckpoint(path,monitor='loss',save_best_only=True,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  483/17034 [..............................] - ETA: 2:25:36 - loss: 1.1022 - acc: 0.6039"
     ]
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 17034,\n",
    "                         epochs = 10,\n",
    "                         callbacks=[mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making new predictions\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 0:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    \n",
    "print(\"The Pet name is\",prediction)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
